{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":320111,"sourceType":"datasetVersion","datasetId":134715}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn import model_selection, metrics\nimport torch\nimport transformers\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-01T12:28:54.964649Z","iopub.execute_input":"2024-09-01T12:28:54.965007Z","iopub.status.idle":"2024-09-01T12:28:55.723574Z","shell.execute_reply.started":"2024-09-01T12:28:54.964975Z","shell.execute_reply":"2024-09-01T12:28:55.722655Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"config = {\n    \"max_length\": 360,\n    \"model_path\": \"microsoft/xtremedistil-l6-h256-uncased\",\n    \n    \"output_dir\": \"./my-model\",\n    \"train_batch_size\": 64,\n    \"valid_batch_size\": 64,\n    \"learning_rate\": 3e-5,\n    \"epochs\": 3,\n    \n    \"debug\": True,\n}","metadata":{"execution":{"iopub.status.busy":"2024-09-01T12:28:59.204950Z","iopub.execute_input":"2024-09-01T12:28:59.205306Z","iopub.status.idle":"2024-09-01T12:28:59.210089Z","shell.execute_reply.started":"2024-09-01T12:28:59.205260Z","shell.execute_reply":"2024-09-01T12:28:59.209179Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"tokenizer = transformers.AutoTokenizer.from_pretrained(config[\"model_path\"])\nclass TextDataset:\n\n    def __init__(self, data):\n        self.data = data\n\n    def __len__(self):\n        return self.data.shape[0]\n\n    def __getitem__(self, idx):\n        row = self.data.iloc[idx]\n\n        enc = enc = tokenizer(\n            row[\"text\"],\n            add_special_tokens=True,\n            max_length=config[\"max_length\"],\n            padding=\"max_length\",\n            truncation=True\n        )\n\n        return {\n            \"input_ids\": torch.tensor(enc[\"input_ids\"]),\n            \"attention_mask\": torch.tensor(enc[\"attention_mask\"]),\n            \"label\": torch.tensor(row[\"label\"]),\n        }","metadata":{"execution":{"iopub.status.busy":"2024-09-01T12:29:00.754738Z","iopub.execute_input":"2024-09-01T12:29:00.755473Z","iopub.status.idle":"2024-09-01T12:29:02.687948Z","shell.execute_reply.started":"2024-09-01T12:29:00.755425Z","shell.execute_reply":"2024-09-01T12:29:02.687012Z"},"trusted":true},"execution_count":7,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/525 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"477923218c264f6f9d85e91f1c88736c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24ce4067b37a4396972501194a13aa6a"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv').rename(columns={\"review\": \"text\"})\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-01T12:31:33.695878Z","iopub.execute_input":"2024-09-01T12:31:33.696275Z","iopub.status.idle":"2024-09-01T12:31:35.170145Z","shell.execute_reply.started":"2024-09-01T12:31:33.696236Z","shell.execute_reply":"2024-09-01T12:31:35.169150Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                                                text sentiment\n0  One of the other reviewers has mentioned that ...  positive\n1  A wonderful little production. <br /><br />The...  positive\n2  I thought this was a wonderful way to spend ti...  positive\n3  Basically there's a family where a little boy ...  negative\n4  Petter Mattei's \"Love in the Time of Money\" is...  positive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"id2label = {0: \"negative\", 1: \"positive\"}\nlabel2id = {label: id_ for id_, label in id2label.items()}\n\ndf[\"label\"] = df[\"sentiment\"].map(label2id)\n\nif config[\"debug\"]:\n    print(\"DEBUG MODE!\")\n    df = df.sample(10_000, random_state=123)\n\nprint(df.shape)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-01T12:31:58.858811Z","iopub.execute_input":"2024-09-01T12:31:58.859186Z","iopub.status.idle":"2024-09-01T12:31:58.892739Z","shell.execute_reply.started":"2024-09-01T12:31:58.859150Z","shell.execute_reply":"2024-09-01T12:31:58.891829Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"DEBUG MODE!\n(10000, 3)\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                                    text sentiment  label\n11872  This movie was beyond awful, it was a pimple o...  negative      0\n40828  As of this writing John Carpenter's 'Halloween...  positive      1\n36400  I must admit a slight disappointment with this...  positive      1\n5166   Oh dear! The BBC is not about to be knocked of...  negative      0\n30273  its a totally average film with a few semi-alr...  negative      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>sentiment</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11872</th>\n      <td>This movie was beyond awful, it was a pimple o...</td>\n      <td>negative</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>40828</th>\n      <td>As of this writing John Carpenter's 'Halloween...</td>\n      <td>positive</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>36400</th>\n      <td>I must admit a slight disappointment with this...</td>\n      <td>positive</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5166</th>\n      <td>Oh dear! The BBC is not about to be knocked of...</td>\n      <td>negative</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>30273</th>\n      <td>its a totally average film with a few semi-alr...</td>\n      <td>negative</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer = transformers.AutoTokenizer.from_pretrained(config[\"model_path\"])","metadata":{"execution":{"iopub.status.busy":"2024-09-01T12:32:20.415837Z","iopub.execute_input":"2024-09-01T12:32:20.416174Z","iopub.status.idle":"2024-09-01T12:32:20.740860Z","shell.execute_reply.started":"2024-09-01T12:32:20.416142Z","shell.execute_reply":"2024-09-01T12:32:20.739904Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"train, valid = model_selection.train_test_split(\n    df,\n    test_size=0.2,\n    random_state=23,\n    shuffle=True,\n    stratify=df[\"label\"]\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-01T12:32:36.646792Z","iopub.execute_input":"2024-09-01T12:32:36.647431Z","iopub.status.idle":"2024-09-01T12:32:36.662141Z","shell.execute_reply.started":"2024-09-01T12:32:36.647392Z","shell.execute_reply":"2024-09-01T12:32:36.661136Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train_ds = TextDataset(train)\nvalid_ds = TextDataset(valid)","metadata":{"execution":{"iopub.status.busy":"2024-09-01T12:32:57.857779Z","iopub.execute_input":"2024-09-01T12:32:57.858142Z","iopub.status.idle":"2024-09-01T12:32:57.862447Z","shell.execute_reply.started":"2024-09-01T12:32:57.858106Z","shell.execute_reply":"2024-09-01T12:32:57.861446Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"model = transformers.AutoModelForSequenceClassification.from_pretrained(config[\"model_path\"])","metadata":{"execution":{"iopub.status.busy":"2024-09-01T12:33:54.548049Z","iopub.execute_input":"2024-09-01T12:33:54.548413Z","iopub.status.idle":"2024-09-01T12:33:57.041538Z","shell.execute_reply.started":"2024-09-01T12:33:54.548380Z","shell.execute_reply":"2024-09-01T12:33:57.040829Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/51.0M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0626e6e664ab4f499af39e19412b64d8"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/xtremedistil-l6-h256-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"def compute_metrics(eval_data):\n   \n    preds = eval_data.predictions.argmax(-1)\n    labels = eval_data.label_ids \n    print(eval_data)\n    print(preds)\n    print(labels)\n\n    return {\n        'accuracy': metrics.accuracy_score(labels, preds),\n        'precision': metrics.precision_score(labels, preds),\n        'recall': metrics.recall_score(labels, preds),\n        'classification_report': metrics.classification_report(labels, preds, target_names=list(id2label.values()), output_dict=True)\n\n\n\n\n    }\n\ntraining_args = transformers.TrainingArguments(\n     output_dir=\"./results\",                      # Directory for storing results\n    eval_strategy=\"steps\",                 # Evaluate every few steps\n    per_device_train_batch_size=config['train_batch_size'],              # Batch size per device during training\n    per_device_eval_batch_size=config['train_batch_size'],               # Batch size per device during evaluation\n    num_train_epochs=config['epochs'],                          # Total number of training epochs\n    warmup_steps=500,                            # Number of warmup steps for learning rate scheduler\n    save_total_limit=2,\n    logging_dir=None,                            # Disable logging directory\n    logging_strategy=\"no\",\n    report_to=[]# Limit the total amount of checkpoints`\n\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-01T12:34:22.491861Z","iopub.execute_input":"2024-09-01T12:34:22.492538Z","iopub.status.idle":"2024-09-01T12:34:22.527011Z","shell.execute_reply.started":"2024-09-01T12:34:22.492494Z","shell.execute_reply":"2024-09-01T12:34:22.526237Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"trainer = transformers.Trainer(\n    model=model,                                 # The model to be trained\n    args=training_args,                          # The training arguments, defined above\n    train_dataset=train_ds,                 # The training dataset\n    eval_dataset=valid_ds,                   # The evaluation dataset\n    tokenizer=tokenizer,                         # The tokenizer\n    compute_metrics=compute_metrics, \n)","metadata":{"execution":{"iopub.status.busy":"2024-09-01T12:34:40.819888Z","iopub.execute_input":"2024-09-01T12:34:40.820968Z","iopub.status.idle":"2024-09-01T12:35:02.129124Z","shell.execute_reply.started":"2024-09-01T12:34:40.820924Z","shell.execute_reply":"2024-09-01T12:35:02.128338Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-09-01T12:35:02.130592Z","iopub.execute_input":"2024-09-01T12:35:02.131853Z","iopub.status.idle":"2024-09-01T12:36:58.910635Z","shell.execute_reply.started":"2024-09-01T12:35:02.131819Z","shell.execute_reply":"2024-09-01T12:36:58.909713Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='189' max='189' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [189/189 01:51, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=189, training_loss=0.5647390860098379, metrics={'train_runtime': 114.9602, 'train_samples_per_second': 208.768, 'train_steps_per_second': 1.644, 'total_flos': 249110795520000.0, 'train_loss': 0.5647390860098379, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.save_state()","metadata":{"execution":{"iopub.status.busy":"2024-09-01T12:36:58.911900Z","iopub.execute_input":"2024-09-01T12:36:58.912583Z","iopub.status.idle":"2024-09-01T12:36:58.917053Z","shell.execute_reply.started":"2024-09-01T12:36:58.912535Z","shell.execute_reply":"2024-09-01T12:36:58.916317Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"trainer.save_model()","metadata":{"execution":{"iopub.status.busy":"2024-09-01T12:36:58.919432Z","iopub.execute_input":"2024-09-01T12:36:58.920024Z","iopub.status.idle":"2024-09-01T12:36:59.025106Z","shell.execute_reply.started":"2024-09-01T12:36:58.919981Z","shell.execute_reply":"2024-09-01T12:36:59.024335Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}